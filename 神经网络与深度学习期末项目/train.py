import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image
import os
from sklearn.model_selection import train_test_split
import numpy as np


# ç®€åŒ–çš„Inceptionæ¨¡å—ï¼Œæ›´å°æ›´å¿«
class InceptionModule(nn.Module):
    def __init__(self, in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool_proj):
        super(InceptionModule, self).__init__()
        # 1x1åˆ†æ”¯
        self.branch1 = nn.Sequential(
            nn.Conv2d(in_channels, ch1x1, kernel_size=1),
            nn.BatchNorm2d(ch1x1),
            nn.ReLU(inplace=True)
        )

        # 1x1åæ¥3x3åˆ†æ”¯
        self.branch2 = nn.Sequential(
            nn.Conv2d(in_channels, ch3x3_reduce, kernel_size=1),
            nn.BatchNorm2d(ch3x3_reduce),
            nn.ReLU(inplace=True),
            nn.Conv2d(ch3x3_reduce, ch3x3, kernel_size=3, padding=1),
            nn.BatchNorm2d(ch3x3),
            nn.ReLU(inplace=True)
        )

        # 1x1åæ¥5x5åˆ†æ”¯
        self.branch3 = nn.Sequential(
            nn.Conv2d(in_channels, ch5x5_reduce, kernel_size=1),
            nn.BatchNorm2d(ch5x5_reduce),
            nn.ReLU(inplace=True),
            nn.Conv2d(ch5x5_reduce, ch5x5, kernel_size=5, padding=2),
            nn.BatchNorm2d(ch5x5),
            nn.ReLU(inplace=True)
        )

        # 3x3æ± åŒ–åæ¥1x1åˆ†æ”¯
        self.branch4 = nn.Sequential(
            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
            nn.Conv2d(in_channels, pool_proj, kernel_size=1),
            nn.BatchNorm2d(pool_proj),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        branch1 = self.branch1(x)
        branch2 = self.branch2(x)
        branch3 = self.branch3(x)
        branch4 = self.branch4(x)

        outputs = [branch1, branch2, branch3, branch4]
        return torch.cat(outputs, 1)


# æ›´ç®€å•ã€æ›´å°çš„GoogleNetæ¨¡å‹
class SimpleGoogleNet(nn.Module):
    def __init__(self, num_classes=7):
        super(SimpleGoogleNet, self).__init__()

        # å‰éƒ¨å·ç§¯å±‚ - ç®€åŒ–
        self.conv1 = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3),  # å‡å°‘é€šé“æ•°
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1)
        )

        # ç®€åŒ–çš„Inceptionæ¨¡å—
        self.inception3a = InceptionModule(32, 16, 24, 32, 4, 8, 8)  # å‡å°‘é€šé“æ•°
        self.inception3b = InceptionModule(64, 32, 32, 48, 8, 16, 16)

        # ä¸­é—´å±‚
        self.conv_mid = nn.Sequential(
            nn.Conv2d(112, 64, kernel_size=1),  # 112æ˜¯inception3bçš„è¾“å‡ºé€šé“æ•°
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1)
        )

        # æ›´å¤šInceptionæ¨¡å—
        self.inception4a = InceptionModule(64, 32, 32, 48, 8, 16, 16)
        self.inception4b = InceptionModule(112, 48, 48, 64, 12, 24, 24)

        # å…¨å±€å¹³å‡æ± åŒ–å’Œå…¨è¿æ¥
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(0.3)
        self.fc = nn.Linear(160, num_classes)  # inception4bçš„è¾“å‡ºé€šé“æ•°

    def forward(self, x):
        # å‰éƒ¨å·ç§¯
        x = self.conv1(x)

        # Inceptionæ¨¡å—
        x = self.inception3a(x)
        x = self.inception3b(x)
        x = self.conv_mid(x)

        x = self.inception4a(x)
        x = self.inception4b(x)

        # åˆ†ç±»
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        x = self.fc(x)

        return F.log_softmax(x, dim=1)


# è®­ç»ƒå‡½æ•°
def train(model, device, train_loader, optimizer, epoch):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # è®¡ç®—å‡†ç¡®ç‡
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)

        if batch_idx % 20 == 0:  # æ›´é¢‘ç¹åœ°æ˜¾ç¤º
            batch_accuracy = 100. * correct / total if total > 0 else 0
            print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '
                  f'({100. * batch_idx / len(train_loader):.0f}%)]\t'
                  f'Loss: {loss.item():.6f}\tBatch Acc: {batch_accuracy:.2f}%')

    avg_loss = running_loss / len(train_loader)
    train_accuracy = 100. * correct / total
    return avg_loss, train_accuracy


# æµ‹è¯•å‡½æ•°
def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = 100. * correct / len(test_loader.dataset)

    print(f'\nTest set: Average loss: {test_loss:.4f}, '
          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\n')
    return test_loss, accuracy


# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class EmotionDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path)

            # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
            if image.mode != 'L':
                image = image.convert('L')

            label = self.labels[idx]

            if self.transform:
                image = self.transform(image)

            return image, label

        except Exception as e:
            # å¦‚æœå›¾ç‰‡åŠ è½½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå ä½ç¬¦
            print(f"Error loading image {img_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»‘è‰²å›¾ç‰‡
            image = Image.new('L', (128, 128))
            label = self.labels[idx]
            if self.transform:
                image = self.transform(image)
            return image, label


def load_emotion_data(data_dir):

    image_paths = []
    labels = []
    label_dict = {}

    # è·å–æ‰€æœ‰æ–‡ä»¶å¤¹å¹¶æŒ‰å­—æ¯æ’åº
    folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])

    for label_idx, emotion_folder in enumerate(folders):
        emotion_path = os.path.join(data_dir, emotion_folder)
        label_dict[label_idx] = emotion_folder

        # éå†è¯¥æƒ…æ„Ÿæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        for img_name in os.listdir(emotion_path):
            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                img_path = os.path.join(emotion_path, img_name)
                image_paths.append(img_path)
                labels.append(label_idx)

    print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡ï¼Œ{len(label_dict)} ä¸ªç±»åˆ«")
    print(f"ç±»åˆ«æ˜ å°„: {label_dict}")

    # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
    unique, counts = np.unique(labels, return_counts=True)
    print("\nç±»åˆ«åˆ†å¸ƒ:")
    for label_idx, count in zip(unique, counts):
        print(f"  {label_dict[label_idx]}: {count} å¼ å›¾ç‰‡ ({100. * count / len(labels):.1f}%)")

    return image_paths, labels, label_dict


def main():
    # 1. é¦–å…ˆæ£€æŸ¥æ•°æ®é›†
    data_dir = "C:\\Users\\hm943\\Downloads\\archive\\processed_data"

    if not os.path.exists(data_dir):
        print(f"é”™è¯¯: æ•°æ®é›†ç›®å½• '{data_dir}' ä¸å­˜åœ¨!")
        return

    # æ£€æŸ¥ç›®å½•å†…å®¹
    print("æ£€æŸ¥æ•°æ®é›†ç›®å½•...")
    folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]
    print(f"æ‰¾åˆ° {len(folders)} ä¸ªç±»åˆ«æ–‡ä»¶å¤¹:")
    for folder in folders:
        folder_path = os.path.join(data_dir, folder)
        img_count = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        print(f"  {folder}: {img_count} å¼ å›¾ç‰‡")

    batch_size = 64
    epochs = 10
    learning_rate = 0.002

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")

    # æ›´ç®€å•çš„æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
    ])

    # åŠ è½½æ•°æ®é›†
    image_paths, labels, label_dict = load_emotion_data(data_dir)

    if len(image_paths) == 0:
        print("é”™è¯¯: æ•°æ®é›†ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡!")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬
    if len(image_paths) < 100:
        print(f"è­¦å‘Š: æ•°æ®é›†åªæœ‰ {len(image_paths)} å¼ å›¾ç‰‡ï¼Œå¯èƒ½å¤ªå°‘!")

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_paths, test_paths, train_labels, test_labels = train_test_split(
        image_paths, labels, test_size=0.2, random_state=42, stratify=labels
    )

    print(f"\nè®­ç»ƒé›†å¤§å°: {len(train_paths)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_paths)}")

    # åˆ›å»ºæ•°æ®é›†
    train_dataset = EmotionDataset(train_paths, train_labels, transform=transform)
    test_dataset = EmotionDataset(test_paths, test_labels, transform=transform)

    # æ£€æŸ¥ä¸€ä¸ªæ ·æœ¬
    print("\næ£€æŸ¥ä¸€ä¸ªè®­ç»ƒæ ·æœ¬...")
    if len(train_dataset) > 0:
        sample_img, sample_label = train_dataset[0]
        print(f"æ ·æœ¬å›¾ç‰‡å½¢çŠ¶: {sample_img.shape}")
        print(f"æ ·æœ¬æ ‡ç­¾: {sample_label} ({label_dict[sample_label]})")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    num_classes = len(label_dict)
    print(f"\nåˆ›å»ºæ¨¡å‹ï¼Œç±»åˆ«æ•°: {num_classes}")

    model = SimpleGoogleNet(num_classes=num_classes).to(device)

    # æ‰“å°æ¨¡å‹ç»“æ„
    print("\næ¨¡å‹ç»“æ„:")
    print(model)

    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\næ€»å‚æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)

    #Adamä¼˜åŒ–å™¨é€šå¸¸ä¸éœ€è¦StepLRï¼Œä½†å¯ä»¥ä¿ç•™ç”¨äºå­¦ä¹ ç‡è¡°å‡
    # å¦‚æœå­¦ä¹ ç‡è¡°å‡æ•ˆæœä¸å¥½ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨ReduceLROnPlateau
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

    train_losses = []
    test_losses = []
    train_accuracies = []
    test_accuracies = []

    best_accuracy = 0.0
    best_model_path = "best_emotion_model.pth"

    print(f"\nå¼€å§‹è®­ç»ƒï¼Œç›®æ ‡: 10ä¸ªepochå†…è¾¾åˆ°80%å‡†ç¡®ç‡")
    print(f"è®­ç»ƒé…ç½®: batch_size={batch_size}, å­¦ä¹ ç‡={learning_rate}, ä¼˜åŒ–å™¨=Adam")

    for epoch in range(1, epochs + 1):
        print(f"\n{'=' * 20} Epoch {epoch}/{epochs} {'=' * 20}")

        # è®­ç»ƒ
        train_loss, train_acc = train(model, device, train_loader, optimizer, epoch)
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # æµ‹è¯•
        test_loss, accuracy = test(model, device, test_loader)
        test_losses.append(test_loss)
        test_accuracies.append(accuracy)

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'accuracy': accuracy,
                'num_classes': num_classes,
                'label_dict': label_dict
            }, best_model_path)
            print(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {accuracy:.2f}%")

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if accuracy >= 80.0:
            print(f"ğŸ‰ å·²è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {accuracy:.2f}%!")
            break

    # ç»˜åˆ¶ç»“æœ
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # æŸå¤±æ›²çº¿
    axes[0].plot(train_losses, label='Training Loss', marker='o')
    axes[0].plot(test_losses, label='Test Loss', marker='s')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Training and Test Loss')
    axes[0].legend()
    axes[0].grid(True)

    # å‡†ç¡®ç‡æ›²çº¿
    axes[1].plot(train_accuracies, label='Training Accuracy', marker='o')
    axes[1].plot(test_accuracies, label='Test Accuracy', marker='s')
    axes[1].axhline(y=80, color='r', linestyle='--', alpha=0.5, label='80% Target')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy (%)')
    axes[1].set_title('Training and Test Accuracy')
    axes[1].legend()
    axes[1].grid(True)
    axes[1].set_ylim([0, 100])

    plt.tight_layout()
    plt.savefig('training_results.png')
    plt.show()

    print("\n" + "=" * 50)
    print("è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åˆ°: {best_model_path}")
    print(f"ç±»åˆ«æ•°é‡: {num_classes}")


if __name__ == '__main__':
    main()